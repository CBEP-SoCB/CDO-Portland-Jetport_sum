---
title: "Frequency Analyses of Weather Events"
author:  "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "11/09/2021"
output:
  github_document:
    toc: true
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center',
                      fig.width = 5, fig.height = 4,
                      collapse = TRUE, comment = "#>")
```

# Introduction
This R Notebook contains code analyzing weather data from the Portland Jetport
for inclusion in the 2020 State of the Bay Report.  The primary focus in on
statistical models, but selected graphics are included to aid interpretation.

This R Notebook focuses on long-term (80 year) changes in frequency of extreme 
events, including cold days, hot days, and high rainfall days.

# Install Libraries
```{r}
library(tidyverse)
library(readr)
library(ggthemes)

library(CBEPgraphics)
load_cbep_fonts()
theme_set(theme_cbep())
```

## Read Data
```{r}
sibfldnm <- 'Data'
parent <- dirname(getwd())
sibling <- paste(parent,sibfldnm, sep = '/')
fn <- 'longannualdata.csv'

longannualdata <- read_csv(paste(sibling,fn, sep = '/')) %>%
  select(-station) %>%
  mutate(year = as.numeric(format(date, format='%Y'))) %>%
  mutate(cyear = year-1980)
```

# Temperature Exceedences
The Annual Data Downloaded from NOAA's Climate Data Online includes counts of 
the number of days exceeding various temperature thresholds, as follows:

1. DX90: Number of days with maximum temperature >= 32.2°C/90°F. 
2. DX70: Number of days with maximum temperature >= 21.1°C/70°F. 
3. DX32: Number of days with maximum temperature <= 0°C/32°F. 
4. DT32: Number of days with minimum temperature <= 0°C/32°F. 
5. DT00: Number of days with minimum temperature <= -17.8°C/0°F. 

We focus on days that got over over 90 Fahrenheit, days that dropped  below 32,
and days  that got as low as 0 degrees F.  Notice that even though the CDO data
was downloaded in metric units, these cumulative counts are based on English
units.
```{r}
textdatalong <- longannualdata %>%
  filter(datatype %in% c('DX90', 'DT32', 'DT00'))

textdata <- longannualdata %>%
  filter(datatype %in% c('DX90', 'DT32', 'DT00')) %>%
  spread(key = datatype, value = value)

# The following is to test binomial GLMs
doy <- tibble(year = 1941:2019, days = rep(365, 2020-1941)) %>%
mutate(days = ifelse((year %% 4 == 0) & (year!=2000), 366, 365))

textdata <- textdata %>%
  mutate(days = doy$days)
```

## Generalized Linear Models
These are count data, suggesting either Poisson or binomial models.
Technically, since the total number of days in a year is limited (to 365 days
-- 366 for leap years), a binomial GLM might be considered correct, but for low
counts, (as observed for most of these variables) the difference is immaterial,
and the assumptions of a Poisson model are adequately met.  For high counts, a
binomial distribution will converge on a normal distribution, suggesting a
standard linear model.

Several variables show evidence of over-dispersion compared to a Poisson model, 
which suggests looking at quasi-Poisson models.

The Poisson Models are convenient in this setting because the canonical link for
the Poisson model is log, which is easier to work with in this setting than the 
canonical link for binomial GLMs (logistic).

### Poisson Models
```{r}  
gt90GLM <- glm(DX90 ~ year, family = poisson, data = textdata)
lt32GLM <- glm(DT32 ~ year, family = poisson, data = textdata)
lt00GLM <- glm(DT00 ~ year, family = poisson, data = textdata)

gt90GLM_q <- glm(DX90 ~ year, family = quasipoisson, data = textdata)
lt32GLM_q <- glm(DT32 ~ year, family = quasipoisson, data = textdata)
lt00GLM_q <- glm(DT00 ~ year, family = quasipoisson, data = textdata)
```

### Other Models
Here we try binomial and Gaussian models, on the days less than freezing data,
to examine whether it is likely that selection of models would have any effect
on our conclusions.

```{r}
#Set up response variable for binomial model
rDT32 <- cbind(textdata$DT32, textdata$days-textdata$DT32)

lt32GLM_b <- glm(rDT32 ~ year, family = binomial, data = textdata)
lt32LM <- lm(DT32 ~ year, data = textdata)
```

### Compare Model Trend Lines
```{r}
logit <- function (p) {log(p/(1-p))}
logistic <- function (p) {exp(p)/(exp(p)+1)}
lines <- tibble(cyr = seq(1941,2019),
          lt32_p = exp(coef(lt32GLM)[1] + coef(lt32GLM)[2] * seq(1941,2019) ),
          lt32_b = 365*logistic(coef(lt32GLM_b)[1] + coef(lt32GLM_b)[2]  * seq(1941,2019) ),
          lt32_l = coef(lt32LM)[1] + coef(lt32LM)[2]*seq(1941,2019) )

plt <- ggplot(textdata, aes(x=year))+
  geom_point(aes(y=DT32)) +
  geom_line(data = lines, aes(x=cyr, y=lt32_p), lty=2, color='blue') +
  geom_line(data = lines, aes(x=cyr, y=lt32_b), lty=2, color='green') +
  geom_line(data = lines, aes(x=cyr, y=lt32_l), lty=2, color='red') +

  xlab('Year') +
  ylab("Days")
plt
```
So, all three models provide nearly identical predictions and qualitative 
conclusions. Thus model selection here is largely immaterial.  We focus on the
Poisson models.

#### Greater than 90 Degree Days
```{r}
summary(gt90GLM)
summary(gt90GLM_q)
```
So no increase in number of days exceeding 90 degrees.  Quasi-Poisson addresses 
the elevated residual deviance, increasing standard errors, but does not change 
the conclusions.

#### Days Freezing
```{r}
summary(lt32GLM)
summary(lt32GLM_q)
```
We see significant declines in the number of days dipping below freezing. The 
quasipoisson model identifies slight under-dispersion, but that does not change 
the underlying conclusions.

##### Model Diagnostics
```{r}
oldpar <- par(mfrow= c(2,2))
plot(lt32GLM)
par(oldpar)
```

We see no consequential deviations from model assumptions, although residuals
show modest deviations from expectations.

#### Days Less Than Zero
```{r}
summary(lt00GLM)
summary(lt00GLM_q)
```
Highly significant decrease in days dropping below zero.  QuasiPoisson addresses
moderate over-dispersion, but does not change the substantive conclusions.  We
prefer the quasi poison model here, as slightly more conservative.

For plotting purposes, note that all model parameters are identical between 
Poisson and Quasi-Poisson models.  It is only the dispersion that differs.

# Precipitation Frequencies
DP01: Number of days with >= 0.01 inch/0.254 millimeter in the month (year).
DP10: Number of days with >= 0.1 inch/2.54 millimeter in the month (year).
DP1X: Number of days with >= 1.0 inch (25.4mm) precipitation in the month (year).
DSNW: Number of days with snowfall >= 1 inch (25 mm).
DSND: Number of days with snow depth >= 1 inch (25 mm).

Note this does not include the number of days with more than two inches of rain,
which is arguably a better metric of intense storms than the one inch rain
threshold.  That needs to be derived from the daily data.

## Load Data
```{r}
pextdata <- longannualdata %>%
  filter(datatype %in% c('DP01', 'DP1X', 'DSNW', 'DSND')) %>%
  select(-attributes) %>%
  spread(key = datatype, value = value)

# Days with two inches of rain or more
fn <- 'longdailydata.csv'

num2inch <- 
  # Read daily data
  read_csv(paste(sibling,fn, sep = '/')) %>%
  select(-station) %>%
  mutate(year = as.numeric(format(date, format='%Y')))  %>%
  select(date,year, datatype, value) %>%
  # Filter down to only precipitation data
  filter(datatype=='PRCP') %>%
  rename(PRCP = value) %>%
  filter( ! is.na(PRCP)) %>%
  # Convert to inches. Original data in tenths of mm
  mutate(PRCP_IN = PRCP * 0.0393700787 / 10) %>% 
  filter(year > 1940) %>%       # 1940 is an incomplete year in the daily data
  
  # And count the number of high rain events
  filter(PRCP_IN >= 2) %>%    # Only days with two inches of rain or more
  group_by(year) %>%
  summarise(COUNT = n())      # use all caps because "count" is a builtin function

## This will be wrong for years that have no large storms, since the Year will  
## get dropped.  We want years with zero intense storms to be included in the 
## data with the value of zero.  One can fix that using a left_join.

pextdata <- left_join(pextdata, num2inch, by='year') %>%
  mutate(COUNT=replace_na(COUNT,0)) %>%
  rename(DP2X = COUNT) %>%
  mutate(cyear = year-1980)

pextdatalong <- pextdata %>%
  gather(key='datatype', value = 'value', -date, -year, -cyear)

rm(sibfldnm, parent, sibling, fn, num2inch)
```

```{r fig.width = 7}
plt <- ggplot(pextdatalong, aes(x=year, color=datatype))+
  geom_point(aes(y=value)) +
  geom_smooth(aes(y = value), method = 'lm') +
  xlab('Year') +
  ylab("Days") +
  scale_color_discrete(name = '',
                     labels = c('Any Precip.',
                                '> 1 inch Precip.', 
                                 '>2 inch Precipitation', 
                                '>1 inch Snow on Ground',
                                '>1 inch Snow Fall'))
plt
```
Those look crappy all on one graph... But only those with large storms are 
statistically significant.

## Poisson Generalized Linear Models
```{r}
gt0GLM <- glm(DP01 ~ year, family = poisson, data = pextdata)
gt1GLM <- glm(DP1X ~ year, family = poisson, data = pextdata)
gt2GLM <- glm(DP2X ~ year, family = poisson, data = pextdata)

gt0GLM_q <- glm(DP01 ~ year, family = quasipoisson, data = pextdata)
gt1GLM_q <- glm(DP1X ~ year, family = quasipoisson, data = pextdata)
gt2GLM_q <- glm(DP2X ~ year, family = quasipoisson, data = pextdata)
```

### Days with Any Precipitation
```{r}
summary(gt0GLM)
summary(gt0GLM_q)
```
No statistically significant trend in days with measurable rainfall.

### Data with More than One Inch of Rainfall
```{r}
summary(gt1GLM)
summary(gt1GLM_q)
```
So, a statistically significant increase in days with one inch or more of rain.

```{r}
oldpar <- par(mfrow= c(2,2))
plot(gt1GLM)
par(oldpar)
```
Nothing scary in there, but there are a few outliers, and in general the
extremes are wider than expected.  Still, the trend is strong, so these 
relativley mild deviations from assumptions are not likely to matter for out
qualitative conclusions.

### Data with More than Two Inches of Rainfall
```{r}
summary(gt2GLM)
summary(gt2GLM_q)
```
So highly statistically significant changes in days with two inches of rain too.


```{r}
oldpar <- par(mfrow= c(2,2))
plot(gt2GLM)
par(oldpar)
```
This model is pretty solid.

# Days with snow
## Poisson GLMs
```{r}
snowgfallGLM <- glm(DSNW ~ year, family = poisson, data = pextdata)
snowgdepGLM <- glm(DSND ~ year, family = poisson, data = pextdata)
snowgfallGLM_q <- glm(DSNW ~ year, family = quasipoisson, data = pextdata)
snowgdepGLM_q <- glm(DSND ~ year, family = quasipoisson, data = pextdata)
```

## Days with Snowfall
```{r}
summary(snowgfallGLM)
summary(snowgfallGLM_q)
```
Days with snowfall have not changed.

# Days With Snow on the Ground
```{r}
summary(snowgdepGLM)
summary(snowgdepGLM_q)
```
Again, no apparent change in days with snow on the ground.  Very noisy data.  
Highly over-dispersed for a Poisson model.  Might be worth exploring alternative 
models.

# 2 inches of rain in 48 hours - -Note reaily possible
Paul Hunt asked about a graphic from our 2009 Climate Change Report showing 2
inches of rain over 48 hours. I believe you would have to derive that figure
from hourly rainfall data, but the data I've accessed has significant gaps and
inconsistencies that I have not yet resolved.

# Net Changes
It's worth looking at what the analyses mean in terms of predicted values for
selected years.  This gives us a gauge of "typical" conditions for each decade,
based on all the available data, not just the data from that decade.

```{r}
newdf <- data.frame(year=c(1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020))
pred <- predict(gt1GLM, newdata=newdf)
cbind(newdf$year, pred, exp(pred))
```
  
```{r}
pred <- predict(gt2GLM, newdata=newdf)
cbind(newdf$year, pred, exp(pred))
```
So, days with more than one inch of rain  have gone from about eight a year to
about thirteen or fourteen a year.  Days with two or more inches of rain have
gone from about one a year to about three a year.